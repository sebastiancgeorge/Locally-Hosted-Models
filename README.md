# ðŸš€ Day 3 â€“ Local AI Chatbot with LLaMA/Mistral (No API Key Needed)

This is part of my **#100DaysOfAI** challenge. On **Day 3**, I built a fully **offline chatbot** using **llama-cpp-python** and an open-source **GGUF model** like TinyLLaMA or Mistral. No API keys, no internet needed â€” just local AI power. 

---

## ðŸŽ¯ Goal

Create a terminal-based chatbot that uses a **locally running LLM**, such as TinyLLaMA or Mistral, through `llama-cpp`.

---

## ðŸ”§ Technologies Used

| Tool              | Purpose                                       |
|-------------------|-----------------------------------------------|
| Python            | Main programming language                     |
| llama-cpp-python  | Runs GGUF models locally                      |
| Hugging Face      | Source for quantized open-source models       |
| Terminal / VS Code| Interface                                     |

---

## ðŸ“¥ Installation & Setup

1. **Install llama-cpp-python**  
   ```bash
   pip install llama-cpp-python
